{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature/Characteristic/Variable/Property/Predictor\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- PCA is a orthogonal linear transformation to transform data to a new **coordinate system**.\n",
    "- It is used as a dimensional reduction techniques in **Exploratory Data Analysis** and **Predictive Analysis/modelling**.\n",
    "- It results in variable minimisation while also minimising corresponding/associated information loss.\n",
    "- For a p set of variables, there are p(p-1)/2 ways of combining pairs for scatter plots which is a way to understand the underlining relationship in the data.\n",
    "- PCA finds the **best linear combinations of variables** that matter the most.\n",
    "### Considerations\n",
    "* Are there too many variables?\n",
    "* Are the variables correlated?\n",
    "* Is losing variable interpretation not a problem?\n",
    "\n",
    "### Key Steps\n",
    "1. Center the data around the origin by subtracting the mean of each variable/column from the dataset.\n",
    "2. Calculate the Covariance Matrix\n",
    "3. Calculate the Eigen vectors andd EigenValues of the Covariant Matrix\n",
    "4. Normalise the Eigenvectors to obtain the orthonormal unit vectors/mutually orthogonal unit vector\n",
    "5. The Covariance Matrix can be diagonalised using the unit vectors\n",
    "6. The diagonal elements represent the variance of each axis/basis\n",
    "7. The variance proportion represented by the eigenvectors can be obtained by dividing the corresponding eigenvalue with the sum of all eigenvalues.\n",
    "\n",
    "### What about the components?\n",
    "- Components denote the linear combination of the original variables.\n",
    "- The first component describe the axis with highest variablity that is it denotes the axis whose changes correspond to highest changes/variability in the target variable.\n",
    "\n",
    "### Intuition \n",
    "- PCA construct its component or line using two criteria\n",
    "    * ensure that variance/spread of the values along the line is maximal(Maximal variance)\n",
    "    * ensure minimisation of reconstruction error/distance from initial position to the new position on the line (Minimum error)\n",
    "    * Variance is obtained by taking average squared distance from the component center\n",
    "    * Error is obtained by taking average squared distance between original data point and the transformed one\n",
    "    * Averaged distance of original datapoints from the principal component center is then equal to the sum of variance and error, thus forming a Pythogoras Triangle\n",
    "    * Thus, the higher the variance, the lower the error since their sum is constant [Pythagoras theorem](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues) \n",
    "\n",
    "- Each principal component ensures orthogonality with previous ones and then impose maximum variance/minimum error conditions on the datapoints transformation.\n",
    "- this is done recursivley till all the principal components are obtained.\n",
    "\n",
    "### Mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pythagoras Theorem]: https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pythagoras Theorem]: https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
